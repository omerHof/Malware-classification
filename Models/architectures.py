
import torch
import torch.nn as nn
import torchvision.models as models
import torch.nn.functional as F

class classification_model_architecture():
    def __init__(self, cfg):
        self.cfg = cfg
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model,self.num_features = self.init_model(self.cfg.model_params['model_arch'])

    def init_model(self, net_name):

        # Define a dictionary to map net names to their corresponding architectures
        architectures = {
            'resnet18': self.resnet_18,
            'resnet34': self.resnet_34,
            'resnet50': self.resnet_50,
            'resnet101': self.resnet_101,
            'vit':self.vit
        }
        model = architectures[net_name]()
        # Freeze the pre-trained layers
        for param in model.parameters():
            param.requires_grad = False

        # Replace the last fully connected layer with a new one
        if not net_name=='vit':
            num_features = model.fc.in_features
            out_features = self.cfg.model_params['num_of_classes'] if self.cfg.mode=='classification' else self.cfg.model_params['embedding_size']
            # model.fc = nn.Linear(num_features, out_features,bias=True)
            model.fc = nn.Identity()
        else:
            model.heads.head = nn.Linear(model.heads.head.in_features, self.cfg.model_params['num_of_classes'])

        # Move model to the device
        return model.to(self.device),num_features

    def resnet_18(self):
        return models.resnet18(pretrained=True)

    def resnet_34(self):
        return models.resnet34(pretrained=True)

    def resnet_50(self):
        return models.resnet50(pretrained=True)

    def resnet_101(self):
        return models.resnet101(pretrained=True)

    def inception_v3(self):
        return models.inception.Inception3(pretrained=True)

    def vit(self):
        return models.vit_h_14()


class siamese_model_architecture():
    def __init__(self, cfg):
        self.cfg = cfg
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self.init_model(cfg)

    def init_model(self, cfg):
        return Siamese(cfg,self.device)


class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.resnet = models.resnet18(pretrained=True)
        num_ftrs = self.resnet.fc.in_features  # Get the number of input features of the last layer (fc layer)

        # Remove the last layer (fc layer) of the ResNet
        self.resnet.fc = nn.Identity()

        # Add your custom layers
        self.fc1 = nn.Linear(num_ftrs, 1024)
        self.dropout1 = nn.Dropout(0.2)
        self.batchnorm1 = nn.BatchNorm1d(1024)
        self.fc2 = nn.Linear(1024, 512)
        self.dropout2 = nn.Dropout(0.2)
        self.batchnorm2 = nn.BatchNorm1d(512)
        self.fc3 = nn.Linear(512, 256)
        self.dropout3 = nn.Dropout(0.2)
        self.fc4 = nn.Linear(256, 128)

    def forward(self, x):
        x = self.cnn(x)  # Pass the input through the ResNet
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = self.batchnorm1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.batchnorm2(x)
        x = F.relu(self.fc3(x))
        x = self.dropout3(x)
        outputs = self.fc4(x)
        return outputs


class Siamese(nn.Module):
    def __init__(self,cfg,device):
        super(Siamese, self).__init__()
        self.cnn_model = classification_model_architecture(cfg)
        in_features = self.cnn_model.num_features
        self.cnn_model = self.cnn_model.model
        self.fc1 = nn.Linear(in_features, 512).to(device)
        self.dropout1 = nn.Dropout(0.2).to(device)
        self.batchnorm1 = nn.BatchNorm1d(512).to(device)
        self.fc2 = nn.Linear(512, 256).to(device)
        self.dropout2 = nn.Dropout(0.2).to(device)
        self.batchnorm2 = nn.BatchNorm1d(256).to(device)
        self.fc3 = nn.Linear(256, 128).to(device)
        # self.dropout3 = nn.Dropout(0.2).to(device)
        # self.fc4 = nn.Linear(256, 128).to(device)

    # def cnn_and_extract(self,cfg):
    #     self.CCN_base_model = classification_model_architecture(cfg)
    #     self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
    #     self.fc1 = nn.Linear(1024, 1024)
    #     self.dropout1 = nn.Dropout(0.2)
    #     self.batchnorm1 = nn.BatchNorm1d(1024)
    #     self.fc2 = nn.Linear(1024, 512)
    #     self.dropout2 = nn.Dropout(0.2)
    #     self.batchnorm2 = nn.BatchNorm1d(512)
    #     self.fc3 = nn.Linear(512, 256)
    #     self.dropout3 = nn.Dropout(0.2)
    #     self.fc4 = nn.Linear(256, 128)

    def forward(self, anchor, positive, negative):
        out1 = self.extract(anchor)
        out2 = self.extract(positive)
        out3 = self.extract(negative)
        return out1, out2, out3

    def extract(self,x):
        x = self.cnn_model(x)  # Pass the input through the ResNet
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = self.batchnorm1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.batchnorm2(x)
        outputs = self.fc3(x)
        # x = self.dropout3(x)
        # outputs = self.fc4(x)
        return outputs


# Define the triplet loss function
class TripletLoss(nn.Module):
    def __init__(self, margin=1.0):
        super(TripletLoss, self).__init__()
        self.margin = margin

    def forward(self, anchor, positive, negative):
        # distance_positive = (anchor - positive).pow(2).sum(1)
        # distance_negative = (anchor - negative).pow(2).sum(1)
        distance_positive = torch.pairwise_distance(anchor, positive)
        distance_negative = torch.pairwise_distance(anchor, negative)
        losses = F.relu(distance_positive - distance_negative + self.margin)
        return losses.sum()